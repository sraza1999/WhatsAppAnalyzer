{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Analyzer\n",
    "Input all the messages from a chat of yours and see all types of different information! What time of the day do you message the most? What day? What are the most used words in your group chat? All these questions can be answered through the visualization of charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from WhatsApp\n",
    "First step would be to get the actual data from WhatsApp so you can follow the tutorial for [Android](https://youtu.be/3TQCfQ2NoeY?t=30) and for [iOS](https://www.zapptales.com/en/how-to-export-whatsapp-chat-android-iphone-ios/e-mail-icloud/) and then save it wherever you have saved this Jupyter Notebook.\n",
    "Do NOT download Media as this is only a text-based analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"watz poppin\"\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions used later\n",
    "def dfToOneComment(df):\n",
    "    oneComment = \"\"\n",
    "    #stop = set(STOPWORDS)\n",
    "    \n",
    "    for comment in df.Content:\n",
    "        comment = str(comment)\n",
    "        tokens = comment.split()\n",
    "        \n",
    "        for t in range(len(tokens)):\n",
    "            tokens[t] = tokens[t].lower()\n",
    "            \n",
    "        oneComment += \" \".join(tokens) + \" \"\n",
    "    return oneComment\n",
    "\n",
    "def addToComment(main, comment):\n",
    "    tokens = comment.split()\n",
    "    for t in range(len(tokens)):\n",
    "        tokens[t] = tokens[t].lower()\n",
    "            \n",
    "    main += \" \".join(tokens) + \" \"\n",
    "    return main\n",
    "\n",
    "def commentsToOne(bigComment, name):\n",
    "    comment = ''\n",
    "    for i in range(len(bigComment)):\n",
    "\n",
    "        comment = addToComment(comment, chatDF[\"Content\"][i])\n",
    "    return comment\n",
    "\n",
    "def wordCloudPlot(fullComment,stop):\n",
    "    wordCloud = WordCloud(width = 900, \n",
    "                          height = 500,\n",
    "                          background_color='white',\n",
    "                          stopwords = stop,\n",
    "                          min_font_size = 10).generate(fullComment)\n",
    "    plt.figure(figsize = (8,8) , facecolor = None)\n",
    "    plt.imshow(wordCloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    return plt\n",
    "    \n",
    "def unique(list1): \n",
    "    # insert the list to the set \n",
    "    list_set = set(list1) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(list_set)) \n",
    "    for x in unique_list: \n",
    "        print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the file into Python so we can separate into different lists\n",
    "Add the name of the file in the readFile() method as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    text = open(file, 'r', encoding='utf-8') # this merely \"opens\" the file, and mentions we want to read it\n",
    "    readText = text.read() # Now it is just one JUGEEE string\n",
    "    separateText = readText.splitlines() # Now we have an array/list of each newline as a separate element \n",
    "    return separateText\n",
    "myChat = readFile('muzOGfile.txt') #INSERT FILE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data\n",
    "Some of the multi line messages are lines of their own. We dont want that and we know that they must be part of the message at i-1 (if they are at index i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (len(myChat))\n",
    "\n",
    "for i in range(len(myChat)):\n",
    "    #print(i)\n",
    "    #print(myChat[i])\n",
    "    # Remember that it is essentially a 2D array since the string can be isolated into its separate elements also \n",
    "    try:\n",
    "        datetime.datetime.strptime(myChat[i].split(',')[0], '%m/%d/%y') \n",
    "    except ValueError: # If its not a date, append it to the end of the previous message, and replace it with 'N' to be deleted later\n",
    "        myChat[i-1] = myChat[i-1] + ' ' + myChat[i]\n",
    "        #print('yeo')\n",
    "        myChat[i] = 'toDelete'\n",
    "    \n",
    "for i in range(len(myChat)):\n",
    "    if myChat[i].split(' ')[0] == 'toDelete':\n",
    "        myChat[i] = 'toDelete'\n",
    "\n",
    "while(True):\n",
    "    try:\n",
    "        myChat.remove('toDelete')\n",
    "    except ValueError:\n",
    "        break\n",
    "\n",
    "print('BLARRRRR')\n",
    "print (len(myChat)) # OKaty now the chat has been cleaned for all multiline messsages to be appended w the message\n",
    "# before, we will take out any other extra messages\n",
    "\n",
    "myChat = [x for x in myChat if ((\"<Media omitted>\" not in x) and (\" changed the subject from \" not in x) and ( \"changed this group's\" not in x) and (\" This message was deleted\" not in x) and (\" You deleted this Message\" not in x)) ]\n",
    "print (len(myChat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into date, time, name, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [myChat[i].split('-')[1].split(':')[0] for i in range(len(myChat))]\n",
    "name = [space.strip(' ') for space in name]\n",
    "\n",
    "if('Messages to this chat and calls are now secured with end' in name):\n",
    "    name.remove('Messages to this chat and calls are now secured with end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [myChat[i].split(',')[0] for i in range(len(myChat))]\n",
    "if('Messages to this chat and calls are now secured with end' in name):\n",
    "    del date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split breaks the string into two elements based on where to break, then we isolate it further and further\n",
    "time = [myChat[i].split(',')[1].split('-')[0] for i in range(len(myChat))]\n",
    "time = [i.strip(' ') for i in time] # strip is a function to be used on a string which will take out a specific char\n",
    "if('Messages to this chat and calls are now secured with end' in name):\n",
    "    del time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content, remember there are some that have no content bc they are NOT a message\n",
    "content = []\n",
    "print (\"before for loop: \" , len(myChat))\n",
    "\n",
    "for i in range(len(myChat)):\n",
    "    if(\": \" in myChat[i]): # we know FORSURE that it is a message\n",
    "        content.append(myChat[i].split(': ')[1])\n",
    "    else:\n",
    "        myChat[i] = None\n",
    "        \n",
    "myChat = [x for x in myChat if x is not None]\n",
    "print (\"after:\" , len(myChat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip all of the different information into one dataframe under their respective columns\n",
    "We also replace the first Name of the first message with the actual user and not 'messages to this chat... encrypted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatDF = pd.DataFrame(list(zip(date, time, name, content)), columns = ['Date','Time','Name','Content'])\n",
    "chatDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting on ALL the messages\n",
    "### 1) word cloud of ALL of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dfToOneComment(chatDF)\n",
    "stop = STOPWORDS # These are the words that will not be included simply because they are super general \n",
    "stop.add(\"lol\")\n",
    "stop.add(\"wa\")\n",
    "wordCloudPlot(text,stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Various graphs related to periods of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to convert the date column to a datetime object\n",
    "This will make it easy to interpret the various dates and create different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatDF[\"Date\"] = pd.to_datetime(chatDF['Date'], format = '%m/%d/%y')\n",
    "chatDF[\"Time\"] = pd.to_datetime(chatDF['Time'], format = '%I:%M %p')\n",
    "\n",
    "chatDF[\"Year\"] = chatDF[\"Date\"].dt.year\n",
    "chatDF[\"Month\"] = chatDF[\"Date\"].dt.month\n",
    "chatDF[\"Weekday\"] = chatDF[\"Date\"].dt.weekday\n",
    "chatDF[\"Day\"] = chatDF[\"Date\"].dt.day\n",
    "chatDF[\"Hour\"] = chatDF[\"Time\"].dt.hour\n",
    "\n",
    "\n",
    "chatDf = chatDF.set_index(pd.DatetimeIndex(chatDF[\"Date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatDF.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Heatmap (By each month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatDF = chatDF.groupby([\"Month\", \"Year\"]).count().reset_index()\n",
    "#print(heatDF)\n",
    "hm = heatDF.pivot( \"Month\",\"Year\", \"Content\") # make the rows by month, the years are the columns and the number of messages are the values\n",
    "#print(\"AFter pivot\")\n",
    "ax = sb.heatmap(hm, cmap = \"Reds\", linewidths= 1,linecolor = 'black',yticklabels = ['Jan','Feb','Mar',\n",
    "                                                                                    'Apr','May','Jun',\n",
    "                                                                                    'Jul','Aug','Sept',\n",
    "                                                                                    'Oct','Nov','Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatDF\n",
    "dAndM = heatDF.pivot(\"Month\",\"Year\",\"Content\")\n",
    "print(dAndM)\n",
    "px.bar(dAndM,barmode='group',title = 'Number of Messages per Month for every year',labels = {1:'Jan',2:'Feb'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Based on Day of Week - Line Polar Graph and Bar Graph\n",
    "This will show the number of messages in relation to the the specific day of the week (Bar graph is commented out)\n",
    "\n",
    "chatDF[\"Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "y1 = np.arange(1, 11)\n",
    "weekdayDF = chatDF.groupby(\"Weekday\").count().reset_index()\n",
    "weekdayDF = weekdayDF[[\"Weekday\",\"Content\"]]\n",
    "weekdayDF = weekdayDF.replace({0:\"Monday\",1:\"Tuesday\",2:\"Wednesday\",3: \"Thursday\", 4:\"Friday\",5: \"Saturday\", 6:\"Sunday\"})\n",
    "simp_bar_plot = weekdayDF.plot.bar(x = 'Weekday', y = 'Content', color = 'Content')\n",
    "#simp_bar_plot.show()\n",
    "#weekdayDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = px.line_polar(weekdayDF, \n",
    "                  r = 'Content', \n",
    "                  theta = 'Weekday', \n",
    "                  line_close = 'True',#color_discrete_sequence=px.colors.sequential.Bluered\n",
    "                  color_discrete_sequence=px.colors.diverging.PiYG)\n",
    "f.update_traces(fill = 'toself')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An hourly analysis\n",
    "How many message sent every single hour? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyDF = chatDF.groupby(\"Hour\").count().reset_index()\n",
    "hourlyDF.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyDF = chatDF.groupby(\"Hour\").count().reset_index()\n",
    "\n",
    "hour_bar = hourlyDF[[\"Hour\", \"Content\"]].plot.bar(x = [\"12am\", \"1am\", \"2am\", \"3am\", \"4am\", \n",
    "                                                       \"5am\", \"6am\", \"7am\", \"8am\",\n",
    "                                                       \"9am\", \"10am\", \"11am\", \"12pm\", \"1pm\", \n",
    "                                                       \"2pm\", \"3pm\", \"4pm\", \"5pm\",\n",
    "                                                       \"6pm\", \"7pm\", \"8pm\", \"9pm\", \"10pm\", \"11pm\"], y = 'Content')\n",
    "\n",
    "hour_bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Most used messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allMFreq = chatDF.Content.value_counts().head(20)\n",
    "allMessagesBar = px.bar(allMFreq, title = 'Most Used messages in group')\n",
    "allMessagesBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Data on a User to User basis\n",
    "We will iterate through all the users and create respective Dataframes that will subsequently contain only that users messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is pretty important, over here we create separate separate data frames based on the user\n",
    "dictDT = {}\n",
    "for name in chatDF[\"Name\"].unique():\n",
    "    userDF = chatDF.loc[(chatDF[\"Name\"] == name), ['Date','Time','Name','Content']]\n",
    "    dictDT[name] = userDF\n",
    "\n",
    "# ***NOW we have a dictionary with the key being the specific user's name and the value being a data frame with ONLY their messages***\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bar plots from most used messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specFreq = []\n",
    "for i in range(len(chatDF[\"Name\"].unique())):\n",
    "    userDF = dictDT[chatDF[\"Name\"].unique()[i]]\n",
    "    print(\"Username: \",chatDF[\"Name\"].unique()[i])\n",
    "    specFreq.append([chatDF[\"Name\"].unique()[i], userDF.Content.value_counts().head(20)]) # Save the name and data frame\n",
    "\n",
    "for i in range(len(chatDF[\"Name\"].unique())):\n",
    "    x = chatDF[\"Name\"].unique()[i] + \"'s Most Used Messages\"\n",
    "    bar = px.bar(specFreq[i][1], title = x )\n",
    "    bar.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop = STOPWORDS\n",
    "stop.add(\"lol\")\n",
    "stop.add(\"lmao\")\n",
    "stop.add(\"media omitted\")\n",
    "allText = []\n",
    "#stop.remove(\"them\")\n",
    "wordclouds = {}\n",
    "for i in range(len(chatDF[\"Name\"].unique())):\n",
    "    print(\"Username: \",chatDF[\"Name\"].unique()[i])\n",
    "    allText.append(dfToOneComment(dictDT[chatDF[\"Name\"].unique()[i]]))\n",
    "    #print(text)\n",
    "    wordclouds[chatDF[\"Name\"].unique()[i]] = wordCloudPlot(allText[i],stop)\n",
    "    print()\n",
    "print(\"Huee durr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
